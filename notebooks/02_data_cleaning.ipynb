{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8908b813",
   "metadata": {},
   "source": [
    "# 02. Data Cleaning & Enrichment\n",
    "\n",
    "**Objective:** Transform raw staging data into high-quality analytics-ready data.\n",
    "**Key Actions:**\n",
    "1.  **Regex Cleaning:** Removed artifacts like `***` and `@@@` from text fields.\n",
    "2.  **Geospatial Enrichment:** Mapped `Ciudad` to a new `Pais` column for Power BI mapping.\n",
    "3.  **Type Casting:** Converted strings to `Float` and `DateTime`.\n",
    "4.  **Logical Normalization:** Fixed inconsistent `Tipo_Producto` classifications using a master dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85edf11",
   "metadata": {},
   "source": [
    "### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "496123cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import re # For Regex\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from database.db_connection import get_db_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74251bf1",
   "metadata": {},
   "source": [
    "### Load Staging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05789c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created engine for database: riwi_ventas_db\n",
      "Loaded 1000000 rows.\n"
     ]
    }
   ],
   "source": [
    "engine = get_db_engine()\n",
    "df = pd.read_sql(\"SELECT * FROM raw_sales\", engine)\n",
    "print(f\"Loaded {len(df)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165f13e",
   "metadata": {},
   "source": [
    "### Standard Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538241dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates before: 15191\n",
      "Rows remaining: 940258\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 940258 entries, 0 to 999999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   Ciudad           940258 non-null  object        \n",
      " 1   Fecha            940258 non-null  datetime64[ns]\n",
      " 2   Producto         940258 non-null  object        \n",
      " 3   Tipo_Producto    940258 non-null  object        \n",
      " 4   Cantidad         940258 non-null  float64       \n",
      " 5   Precio_Unitario  940258 non-null  float64       \n",
      " 6   Tipo_Venta       940258 non-null  object        \n",
      " 7   Tipo_Cliente     940258 non-null  object        \n",
      " 8   Descuento        940258 non-null  float64       \n",
      " 9   Costo_Envio      940258 non-null  float64       \n",
      " 10  Total            940258 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(5), object(5)\n",
      "memory usage: 86.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Remove Special Characters (Regex) from Text Columns\n",
    "text_cols = ['Ciudad', 'Producto', 'Tipo_Producto', 'Tipo_Venta', 'Tipo_Cliente']\n",
    "for col in text_cols:\n",
    "    # Remove anything that isn't a letter, number, or space\n",
    "    df[col] = df[col].astype(str).str.replace(r'[^\\w\\s]', '', regex=True).str.strip().str.title()\n",
    "\n",
    "# Fix Numeric Columns (Coerce errors to NaN)\n",
    "numeric_cols = ['Cantidad', 'Precio_Unitario', 'Descuento', 'Costo_Envio', 'Total']\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Fix Date\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'], errors='coerce')\n",
    "\n",
    "# Handle Nulls & Duplicates\n",
    "print(f\"Duplicates before: {df.duplicated().sum()}\")\n",
    "df_clean = df.drop_duplicates().dropna().copy()\n",
    "print(f\"Rows remaining: {len(df_clean)}\")\n",
    "\n",
    "# Check types\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb530af",
   "metadata": {},
   "source": [
    "### Data Enrichment (Adding Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744cd5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmapped Cities: ['None']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>Pais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antofagasta</td>\n",
       "      <td>Chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monterrey</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Valparaíso</td>\n",
       "      <td>Chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sevilla</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sevilla</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ciudad    Pais\n",
       "0  Antofagasta   Chile\n",
       "1    Monterrey  Mexico\n",
       "2   Valparaíso   Chile\n",
       "3      Sevilla   Spain\n",
       "4      Sevilla   Spain"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean City Names first (Remove spacing/symbols before mapping)\n",
    "df['Ciudad'] = df['Ciudad'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Define Mapping Dictionary\n",
    "city_to_country = {\n",
    "    'Antofagasta': 'Chile',\n",
    "    'Santiago': 'Chile',\n",
    "    'Valparaíso': 'Chile',\n",
    "    'Valparaiso': 'Chile', # Just in case without accent\n",
    "    'Concepción': 'Chile',\n",
    "    'Concepcion': 'Chile',\n",
    "    \n",
    "    'Bogotá': 'Colombia',\n",
    "    'Bogota': 'Colombia',\n",
    "    'Medellín': 'Colombia',\n",
    "    'Medellin': 'Colombia',\n",
    "    'Cali': 'Colombia',\n",
    "    'Barranquilla': 'Colombia',\n",
    "    'Cartagena': 'Colombia',\n",
    "    'Bucaramanga': 'Colombia',\n",
    "    'Pereira': 'Colombia',\n",
    "    \n",
    "    'Ciudad De México': 'Mexico',\n",
    "    'Ciudad De Mexico': 'Mexico',\n",
    "    'Monterrey': 'Mexico',\n",
    "    'Guadalajara': 'Mexico',\n",
    "    'Puebla': 'Mexico',\n",
    "    'Tijuana': 'Mexico',\n",
    "    \n",
    "    'Buenos Aires': 'Argentina',\n",
    "    'Córdoba': 'Argentina',\n",
    "    'Cordoba': 'Argentina',\n",
    "    'Rosario': 'Argentina',\n",
    "    'Mendoza': 'Argentina',\n",
    "    \n",
    "    'Lima': 'Peru',\n",
    "    'Cusco': 'Peru',\n",
    "    'Arequipa': 'Peru',\n",
    "    'Trujillo': 'Peru',\n",
    "    \n",
    "    'Madrid': 'Spain',\n",
    "    'Barcelona': 'Spain',\n",
    "    'Valencia': 'Spain',\n",
    "    'Sevilla': 'Spain',\n",
    "    \n",
    "    'New York': 'USA',\n",
    "    'Los Angeles': 'USA',\n",
    "    'Chicago': 'USA',\n",
    "    'Houston': 'USA',\n",
    "    'Miami': 'USA'\n",
    "}\n",
    "\n",
    "# Create the 'Pais' column\n",
    "# map() will look up the city and assign the country.\n",
    "df['Pais'] = df['Ciudad'].map(city_to_country)\n",
    "\n",
    "# Check for unmapped cities and print them\n",
    "unmapped = df[df['Pais'].isna()]['Ciudad'].unique()\n",
    "print(f\"Unmapped Cities: {unmapped}\")\n",
    "\n",
    "# Preview\n",
    "df[['Ciudad', 'Pais']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1d0f2",
   "metadata": {},
   "source": [
    "### Final Polish (Remove None & Fix Categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac2d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "- Cities 'None' removed. Remaining rows: 935966\n",
      "- Product categories standardized.\n"
     ]
    }
   ],
   "source": [
    "# Remove the \"None\" city artifact\n",
    "df_clean = df_clean[df_clean['Ciudad'] != 'None'].copy()\n",
    "\n",
    "# Standardize Product Categories (Logical Fix)\n",
    "product_mapping = {\n",
    "    'Arepa': 'Harinas',\n",
    "    'Leche': 'Lácteos',\n",
    "    'Cereal': 'Despensa',\n",
    "    'Queso': 'Lácteos',\n",
    "    'Chocolate': 'Dulces',\n",
    "    'Yogurt': 'Lácteos',\n",
    "    'Galletas': 'Dulces',\n",
    "    'Pan': 'Panadería',\n",
    "    'Gaseosa': 'Bebidas',\n",
    "    'Té': 'Bebidas',\n",
    "    'Café': 'Bebidas',\n",
    "    'Mantequilla': 'Lácteos'\n",
    "}\n",
    "\n",
    "# Overwrite Product_Type with the correct static mapping\n",
    "df_clean['Tipo_Producto'] = df_clean['Producto'].map(product_mapping).fillna(df_clean['Tipo_Producto'])\n",
    "\n",
    "print(\"Validation:\")\n",
    "print(f\"- Cities 'None' removed. Remaining rows: {len(df_clean)}\")\n",
    "print(\"- Product categories standardized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a20ef",
   "metadata": {},
   "source": [
    "### Load to Data Warehouse (Clean Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd3a3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 935966 rows to 'clean_sales'...\n",
      "Success! Pipeline finished.\n"
     ]
    }
   ],
   "source": [
    "table_name = 'clean_sales'\n",
    "\n",
    "try:\n",
    "    print(f\"Saving {len(df_clean)} rows to '{table_name}'...\")\n",
    "    df_clean.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        if_exists='replace',\n",
    "        index=False,\n",
    "        chunksize=10000\n",
    "    )\n",
    "    print(\"Success! Pipeline finished.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to DB: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e4049",
   "metadata": {},
   "source": [
    "## Export\n",
    "Clean data exported to PostgreSQL table `clean_sales`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
